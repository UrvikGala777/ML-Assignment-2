import streamlit as st
import pandas as pd
import pickle
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, precision_score, recall_score, f1_score, matthews_corrcoef

# Page Configuration
st.set_page_config(page_title="ML Classification App", layout="wide")

st.title("ðŸ”¬ Breast Cancer Classification Dashboard")
st.markdown("Build for BITS Pilani ML Assignment 2")

# Sidebar for Model Selection
st.sidebar.header("Model Configuration")
model_options = [
    "Logistic Regression", 
    "Decision Tree", 
    "KNN", 
    "Naive Bayes", 
    "Random Forest", 
    "XGBoost"
]
selected_model_name = st.sidebar.selectbox("Select ML Model", model_options)

# Helper: Load Model and Scaler
@st.cache_resource
def load_resources(model_name):
    filename = f"model/{model_name.replace(' ', '_').lower()}.pkl"
    try:
        with open(filename, 'rb') as f:
            model = pickle.load(f)
        with open('model/scaler.pkl', 'rb') as f:
            scaler = pickle.load(f)
        return model, scaler
    except FileNotFoundError:
        st.error(f"Model file {filename} not found. Please run train_models.py first.")
        return None, None

model, scaler = load_resources(selected_model_name)

# Main Section: File Upload
st.subheader("1. Upload Test Data (CSV)")
uploaded_file = st.file_uploader("Upload your test dataset (must contain feature columns)", type=["csv"])

if uploaded_file is not None and model is not None:
    # Load Data
    df = pd.read_csv(uploaded_file)
    st.write("Data Preview:", df.head())

    # Check for target column to calculate metrics
    target_col = 'target'  # Default target name from our generation script
    
    if target_col in df.columns:
        X_test = df.drop(columns=[target_col])
        y_test = df[target_col]
        
        # Scaling logic (only for specific models)
        if selected_model_name in ["Logistic Regression", "KNN"]:
            X_test_processed = scaler.transform(X_test)
        else:
            X_test_processed = X_test

        # Predictions
        if st.button("Run Prediction"):
            y_pred = model.predict(X_test_processed)
            y_prob = model.predict_proba(X_test_processed)[:, 1]

            # Metrics Calculation
            acc = accuracy_score(y_test, y_pred)
            auc = roc_auc_score(y_test, y_prob)
            prec = precision_score(y_test, y_pred)
            rec = recall_score(y_test, y_pred)
            f1 = f1_score(y_test, y_pred)
            mcc = matthews_corrcoef(y_test, y_pred)

            # Display Metrics
            st.subheader("2. Model Performance Metrics")
            col1, col2, col3, col4, col5, col6 = st.columns(6)
            col1.metric("Accuracy", f"{acc:.2f}")
            col2.metric("AUC", f"{auc:.2f}")
            col3.metric("Precision", f"{prec:.2f}")
            col4.metric("Recall", f"{rec:.2f}")
            col5.metric("F1 Score", f"{f1:.2f}")
            col6.metric("MCC", f"{mcc:.2f}")

            # Confusion Matrix
            st.subheader("3. Visualizations")
            col_viz1, col_viz2 = st.columns(2)
            
            with col_viz1:
                st.markdown("**Confusion Matrix**")
                cm = confusion_matrix(y_test, y_pred)
                fig, ax = plt.subplots()
                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)
                st.pyplot(fig)

            with col_viz2:
                st.markdown("**Classification Report**")
                report = classification_report(y_test, y_pred, output_dict=True)
                st.dataframe(pd.DataFrame(report).transpose())

    else:
        st.warning(f"Dataset must contain a '{target_col}' column for evaluation.")
else:
    st.info("Please upload a CSV file to proceed. (Use 'test_data.csv' generated by train_models.py)")